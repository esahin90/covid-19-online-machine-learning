{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21b70b3f-26e1-4da7-ae60-dcc4f3c93d2c",
   "metadata": {},
   "source": [
    "# Online model definition, data preparation and example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b8caf0-aa5d-4f52-8a75-d5b355f46cc9",
   "metadata": {},
   "source": [
    "## Table of Content\n",
    "1. [Model definition](#model-def)\n",
    "    * [Linear Regression](#linear-regression)\n",
    "    * [Passive-aggressive Regressor](#pa-regressor)\n",
    "2. [Upload model to chantilly](#chantilly-rest)\n",
    "3. [Download GoogleCloudPlatform/covid-19-open-data](#download-dataset)\n",
    "4. [Simulate data stream and view live dashboard for model evaluation](#simulate)\n",
    "    * [Open Chantilly dashboard](#dashboard)\n",
    "5. [Data preparation](#data-prep)\n",
    "    * [Filter by state Bremen](#bremen-data)\n",
    "    * [Merge vaccination data](#vaccination-data)\n",
    "6. [Example predict, learn and measure metric including vaccination data](#example-vaccination)\n",
    "    * [SNARIMAX model definition](#snarimax)\n",
    "    * [Pick one feature x and label y](#pick-one)\n",
    "    * [Define metrics for evaluation of the mode](#metric-eval)\n",
    "    * [Walkthrough prediction, metric update & training](#walkthrough)\n",
    "    * [Full cycle of predict, metric update & train on vaccination data](#full-loop)\n",
    "7. [Playground](#playground)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235a0c38-54fc-4684-8c06-45104343361b",
   "metadata": {},
   "source": [
    "## 1. Model definition <a class=\"anchor\" id=\"model-def\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de8d281-e120-44c5-8cf6-df73a6808bcb",
   "metadata": {},
   "source": [
    "Creme is used for defining our online machine learning models, which can be trained and predict by one sample at a time\n",
    "\n",
    "More information about creme can be found here: https://github.com/MaxHalford/creme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec56642d-ea93-4404-a545-36362d75f380",
   "metadata": {},
   "source": [
    "##### Pipeline definition\n",
    "1. To include the date inside the linear regression, we're first transforming it into a unix timestamp with compose.FuncTransformer.\n",
    "2. Then compose.Select is used to specify, what our input features are to train the model on.\n",
    "3. For standardizing and scaling down the input values, preprocessing.StandardScaler is used, which scales each input feature by subtracting the mean and dividing by the standard deviation to shift the distribution to have a mean of zero and a standard deviation of one.\n",
    "4. As the last step the disered model is define."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c31beca-7547-4d0c-bfc3-2b14fd0eba16",
   "metadata": {},
   "source": [
    "Choose one of the following models for uploading to chantilly by executing the cell or define your own model with creme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9839ce-afeb-4157-bf99-0daed7c28dd1",
   "metadata": {},
   "source": [
    "### Linear Regression <a class=\"anchor\" id=\"linear-regression\"></a>\n",
    "Linear Regression is a basic linear model, which assumes a linear relationship input variables and the output variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e843808-db11-4522-a3b0-1095c5462b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from creme import compose\n",
    "from creme import linear_model\n",
    "from creme import preprocessing\n",
    "\n",
    "\n",
    "def parse(row):\n",
    "    import datetime as dt\n",
    "    row['date'] = dt.datetime.fromisoformat(row['date']).timestamp()\n",
    "    return row\n",
    "\n",
    "model = compose.FuncTransformer(parse) \\\n",
    "    | compose.Select('date', 'new_deceased', 'new_recovered',\n",
    "                     'cumulative_confirmed', 'cumulative_deceased',\n",
    "                     'cumulative_recovered') \\\n",
    "    | preprocessing.StandardScaler() \\\n",
    "    | linear_model.LinearRegression()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce63e169-f05a-4930-8dd4-24cdcdbb1175",
   "metadata": {},
   "source": [
    "### Passive-aggressive Regressor <a class=\"anchor\" id=\"pa-regressor\"></a>\n",
    "The passive-aggressive regressor is model, which aims to learn from large-scale data and is defined by:\n",
    "\n",
    "* Passive: If the prediction is correct, keep the model and do not make any changes.\n",
    "* Aggressive: If the prediction is incorrect, make changes to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6414cb2e-2f44-45ea-b454-d1b6646ab73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from creme import compose\n",
    "from creme import linear_model\n",
    "from creme import preprocessing\n",
    "\n",
    "def parse(row):\n",
    "    import datetime as dt\n",
    "    row['date'] = dt.datetime.fromisoformat(row['date']).timestamp()\n",
    "    return row\n",
    "\n",
    "model = compose.FuncTransformer(parse) \\\n",
    "    | compose.Select('date', 'new_deceased', 'new_recovered',\n",
    "                     'cumulative_confirmed', 'cumulative_deceased',\n",
    "                     'cumulative_recovered') \\\n",
    "    | preprocessing.StandardScaler() \\\n",
    "    | linear_model.PARegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e374b1-c300-4c2d-b2ee-376435690500",
   "metadata": {},
   "source": [
    "## 2. Upload model to chantilly <a class=\"anchor\" id=\"chantilly-rest\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12802251-c38c-4056-a715-91a26cf1a439",
   "metadata": {},
   "source": [
    "The model is uploaded via a REST-API to chantilly, which then can be used our trained through REST-Requests. To serialize the payload for the REST-Request, dill is used to pickle the model.\n",
    "\n",
    "More information about chantilly can be found here: https://github.com/online-ml/chantilly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a583f3d9-b2c6-4d58-b496-12c84ed27b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import requests\n",
    "\n",
    "requests.post('http://localhost:5000/api/model', data=dill.dumps(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5e8f01-c77a-401e-a55c-ac4714c73f45",
   "metadata": {},
   "source": [
    "## 3. Download GoogleCloudPlatform/covid-19-open-data <a class=\"anchor\" id=\"download-dataset\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e02ac11-e863-439a-a948-634396ef44df",
   "metadata": {},
   "source": [
    "In this tutorial the COVID-19 Open-Data dataset is used. It attemps to assemble the largest Covid-19 epidemiological database.\n",
    "More information about the dataset can be found here: https://github.com/GoogleCloudPlatform/covid-19-open-data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f848ced1-9648-498a-a4af-42c59a052040",
   "metadata": {},
   "source": [
    "First we need to download the base epidemiology.csv, which lists the numbers for new cases, tests, recovered & deceased.\n",
    "The schema definition can be found here: [Epidemiology Schema](https://github.com/GoogleCloudPlatform/covid-19-open-data/blob/main/docs/table-epidemiology.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034341a1-b212-4173-8c65-cb0796fc116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://storage.googleapis.com/covid19-open-data/v3/epidemiology.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c2aceb-2013-4756-86ec-0ac3615a7333",
   "metadata": {},
   "source": [
    "For the example inside this notebook we're also using the vaccination dataset, which lists the numbers for new vaccinations, etc..The schema definition can be found here: [Vaccinations Schema](https://github.com/GoogleCloudPlatform/covid-19-open-data/blob/main/docs/table-vaccinations.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b93c6d-aabf-4027-aa13-d54f09693c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://storage.googleapis.com/covid19-open-data/v3/vaccinations.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c331da-3586-4506-aae0-8aa0e48d2865",
   "metadata": {},
   "source": [
    "## 4. Simulate data stream and view live dashboard for model evaluation <a class=\"anchor\" id=\"simulate\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9ba349-80b3-4557-83a0-32b90e8bbd6e",
   "metadata": {},
   "source": [
    "For simulating a data stream and evaluating different models the python script `simulate.py` was developed.\n",
    "\n",
    "```\n",
    "# python simulate.py --help\n",
    "usage: simulate.py [-h] [--file [FILE]] [speed_up]\n",
    "\n",
    "positional arguments:\n",
    "  speed_up\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help     show this help message and exit\n",
    "  --file [FILE]\n",
    "```\n",
    "\n",
    "The script will use `epidemiology.csv` as a default filepath to simulate a data stream for our specific case. You can also specify a custom filepath by using --file like `python --file bremen_epidemiology.csv` for example, if you continue with the notebook and create the dataset for the state Bremen in Germany.\n",
    "The sleep timer is currently set to 1 second between each, which can be speeded up with a positional argument, when starting the script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca940714-8636-4dd9-b30a-b7172b6e0914",
   "metadata": {},
   "source": [
    "There are two ways to use this script. Either run it in the cell below, which will spam the notebook. Or start a new terminal in jupyterlab and execute the python script in the terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1cdafd-9777-4d4a-9c2b-c3bb702b7994",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python simulate.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96decfa-0fff-4efd-913c-de58a9ee54ef",
   "metadata": {},
   "source": [
    "### Open Chantilly dashboard <a class=\"anchor\" id=\"dashboard\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6b4177-3d36-4ff9-97a4-1760452b2616",
   "metadata": {},
   "source": [
    "To evaluate the performance of the model, which was uploaded to chantilly, open [Chantilly Dashboard](http://localhost:5000)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460c8501-1223-4c0b-8a9e-6a8ddda1c332",
   "metadata": {},
   "source": [
    "## 5. Data preparation <a class=\"anchor\" id=\"data-prep\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa6b4f4-ea3a-41a1-ae84-cf1b3a5ec6a7",
   "metadata": {},
   "source": [
    "In this sections we're trying to parse and prepare the data to only contain the state Bremen in Germany and clean up columns and rows, which contain NaN-values. For this we're using pandas, which is widely used in the data science community and is also open source.\n",
    "\n",
    "More information can be found here: https://pandas.pydata.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff47ce5e-22ac-472d-878b-a208a7b83d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b01eb49-16c2-490c-a7e0-1a1d8d6a31fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('epidemiology.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a4b950-bf1a-4af4-bc50-4bcbac77a899",
   "metadata": {},
   "source": [
    "#### Filter by state Bremen (DE_HB) <a class=\"anchor\" id=\"bremen-data\"></a>\n",
    "\n",
    "The location key of the specific region is built by using a combination of codes. See [GoogleCloudPlatform/covid-19-open-data](https://github.com/GoogleCloudPlatform/covid-19-open-data) for more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bed6eb3-0839-4467-a552-e90d2192a0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bremen_data = data[data.location_key.apply(lambda x: \"DE_HB\" == x if isinstance(x, str) else False)]\n",
    "# Drop na columns with no data\n",
    "bremen_data = bremen_data.drop(columns=[\"new_tested\", \"cumulative_tested\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b27c826-585d-4ca1-9685-dc988a90af3e",
   "metadata": {},
   "source": [
    "#### Quick look inside our dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc26ee65-781e-49d0-bb80-6712715c4199",
   "metadata": {},
   "source": [
    "To understand how our dataframe looks like, a quick and easy way is to use head(), which prints the first five rows inside our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c12b355-8f95-4ac3-a388-d568e0213be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bremen_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7682e369-c6f3-4def-abc4-ae82530c3abc",
   "metadata": {},
   "source": [
    "An easy way to have a quick overview of the value in pandas, which we're trying to predict, is to use describe() on the Series, which outputs basic statiscal values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a54913-0e1d-4ee1-8d11-5f2b552e988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bremen_data.new_confirmed.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a0a3a7-c122-43e3-9611-cb200b9399f2",
   "metadata": {},
   "source": [
    "To export the dataframe in a csv-file, to_csv(path) can be used, which will create a new csv-file with the data from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d226025-d3bb-424a-b248-a1a8c47761d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bremen_data.to_csv(\"bremen_epidemiology.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877cb4f5-a0ea-4e07-bad8-74857f1013ed",
   "metadata": {},
   "source": [
    "### Merge vaccination data <a class=\"anchor\" id=\"vaccination-data\"></a>\n",
    "\n",
    "Here we're trying to parse the vaccination data and merge it with the epidemiology dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0009e23-0d43-42f4-a35e-82b7ef52ca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacc_data = pd.read_csv('vaccinations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39caf03c-24d1-403b-aaf8-f8f74dbca0f4",
   "metadata": {},
   "source": [
    "To merge the dataframes we need to select the unqiue identifiers on both dataframes, which are the date and the location_key. Pandas provides an merge-function, which only uses the both dataframes as input parameters and a list of unique-identifiers, which are used to merge the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20ecd47-b3dd-4edd-8316-1ee34c86f389",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(data, vacc_data, on=['date', 'location_key'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f172576-8cfe-4646-8985-a4f94ac9631f",
   "metadata": {},
   "source": [
    "Filter again for the state Bremen in Germany (DE_HB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df22e831-4dae-4678-907f-e67adfb32011",
   "metadata": {},
   "outputs": [],
   "source": [
    "bremen_vacc_data = merged_data[merged_data.location_key.apply(lambda x: \"DE_HB\" == x if isinstance(x, str) else False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec99e78e-b3ba-4e73-a1c4-2c534c1ae079",
   "metadata": {},
   "source": [
    "Select specific columns, which we want to include in our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483d8c34-633a-438e-82de-f3ca615ca4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bremen_vacc_data = bremen_vacc_data[['date', 'location_key', 'new_confirmed', 'new_deceased',\n",
    "       'new_recovered', 'cumulative_confirmed', 'cumulative_deceased',\n",
    "       'cumulative_recovered', 'new_persons_vaccinated',\n",
    "       'cumulative_persons_vaccinated', 'new_persons_fully_vaccinated',\n",
    "       'cumulative_persons_fully_vaccinated', 'new_vaccine_doses_administered',\n",
    "       'cumulative_vaccine_doses_administered']]\n",
    "# Drop na rows\n",
    "bremen_vacc_data = bremen_vacc_data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a726dd54-fa04-4076-aede-cc3fc0170b54",
   "metadata": {},
   "source": [
    "Quick look inside the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028cc954-14ce-4563-9ff0-7c816c6f01f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bremen_vacc_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d96c17-b0b4-478c-88fd-f3e78e3bc689",
   "metadata": {},
   "source": [
    "Describe can also be used on a dataframe, which will generate all the basic statistical values for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bfc5b4-b1b8-4d46-9add-9bfb7bedc2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bremen_vacc_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d70c516-6eca-4129-a4d5-a455fce47df7",
   "metadata": {},
   "source": [
    "## 6. Example predict, learn and measure metric including vaccination data <a class=\"anchor\" id=\"example-vaccination\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f04f55b-0e21-471a-a5ba-e87b28a08786",
   "metadata": {},
   "source": [
    "Since the dataset including vaccinations for Bremen seems to be pretty small currently, we wanted to demonstrate, how the basic workflow with creme looks like. One of the models called SNARIMAX, which we wanted to test on chantilly, also had some problems with the compatibility. Therefore we decided to only use it also in this example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1261a7e8-5ddf-413f-87bf-c7b357424ebd",
   "metadata": {},
   "source": [
    "### SNARIMAX model definition <a class=\"anchor\" id=\"snarimax\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87614534-9a11-4cac-b431-bb6a9f87a729",
   "metadata": {},
   "source": [
    "SNARIMAX stands for (S)easonal (N)on-linear (A)uto(R)egressive (I)ntegrated (M)oving-(A)verage with e(X)ogenous inputs model.\n",
    "\n",
    "This model generalizes many established time series models in a single interface that can be trained online. It assumes that the provided training data is ordered in time and is uniformly spaced.\n",
    "\n",
    "Documentation to the model can be found here: https://riverml.xyz/dev/api/time-series/SNARIMAX/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba221f4-ffe8-4d16-8f21-08b5bbb1a0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from creme import compose\n",
    "from creme import linear_model\n",
    "from creme import preprocessing\n",
    "from creme import time_series\n",
    "\n",
    "def parse(row):\n",
    "    import datetime as dt\n",
    "    row['date'] = dt.datetime.fromisoformat(row['date']).toordinal()\n",
    "    return row\n",
    "\n",
    "model = compose.FuncTransformer(parse) \\\n",
    "    | compose.Select('date', 'new_deceased', 'new_recovered', 'cumulative_confirmed',\n",
    "                     'cumulative_deceased', 'cumulative_recovered', 'new_persons_vaccinated',\n",
    "                     'cumulative_persons_vaccinated', 'new_persons_fully_vaccinated',\n",
    "                     'cumulative_persons_fully_vaccinated', 'new_vaccine_doses_administered',\n",
    "                     'cumulative_vaccine_doses_administered') \\\n",
    "    | time_series.SNARIMAX(p=1, d=1, q=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127f2726-99c1-45a0-9df7-b8e37d5f59ee",
   "metadata": {},
   "source": [
    "### Pick one feature x and label y <a class=\"anchor\" id=\"pick-one\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83b8bf9-e679-4d7a-8251-c0c47572cad6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dict = bremen_vacc_data.to_dict(orient=\"records\")[-1]\n",
    "y = test_dict.pop(\"new_confirmed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc094b4-b0dc-4688-b40b-dc10f1bdf6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f243d84b-db18-49bc-a86b-50523ecb2550",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc97380-6014-47af-a91b-244d026dec4c",
   "metadata": {},
   "source": [
    "### Define metrics for evaluation of the model <a class=\"anchor\" id=\"metric-eval\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad199308-3abc-43c5-9602-892552ab695c",
   "metadata": {},
   "source": [
    "SMAPE stands (S)ymmetric (M)ean (A)bsolute (P)ercentage (E)rror and is used to evaluate the absolute percentage error in respect to the actual ground truth. This metric gives a good representation, how the model is performing and learning over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d40485-2c00-4230-84a2-6673ded7f3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from creme import metrics\n",
    "smape = metrics.SMAPE()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60adbeee-bd83-45e7-9393-6cdbf6e17448",
   "metadata": {},
   "source": [
    "### Walkthrough prediction, metric update & training <a class=\"anchor\" id=\"walkthrough\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e42b98-4d52-4d47-a195-d6518d450f84",
   "metadata": {},
   "source": [
    "Predict value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6940dfba-286a-4721-83fb-361abda0a6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.forecast(horizon=1, xs=[test_dict.copy()])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e9666e-2536-44c4-bb27-45d9096c8f55",
   "metadata": {},
   "source": [
    "Update metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572c6f4d-2298-44e8-942b-0bc86c09f647",
   "metadata": {},
   "outputs": [],
   "source": [
    "smape.update(y_true=y, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f52dfd3-c11a-4c3d-9573-e8fd364f2bb6",
   "metadata": {},
   "source": [
    "Train model on actual value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d246e8-fa10-48bf-9084-00befad54806",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_one(x=test_dict.copy(), y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ee67a1-8b2e-48a5-bd1e-e20fafa86a9a",
   "metadata": {},
   "source": [
    "Repeat prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ea7ff8-6a86-44bb-b94c-059002b5b1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forecast(horizon=1, xs=[test_dict.copy()])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53399e5d-798f-4944-87dc-51f3642b7f1c",
   "metadata": {},
   "source": [
    "### Full cycle of predict, metric update & train on vaccination data <a class=\"anchor\" id=\"full-loop\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4dcfcf-0023-4243-817c-49e73fcaacd7",
   "metadata": {},
   "source": [
    "This is how a continuous loop of prediction, metric update and training on the merged vaccination dataframe could look like. A sleep timer of one second is used in the for loop to see the training process and metric improvement per cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43aa20ec-1883-40fb-a8ac-04f25fec06ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "for data_dict in bremen_vacc_data.to_dict(orient=\"records\"):\n",
    "    y = data_dict.pop(\"new_confirmed\")\n",
    "    y_pred = model.forecast(horizon=1, xs=[test_dict.copy()])[0]\n",
    "    smape.update(y_true=y, y_pred=y_pred)\n",
    "    model.fit_one(x=test_dict.copy(), y=y)\n",
    "    print(f\"Prediction: {y_pred}, Truth: {y}, SMAPE: {smape.get()}\")\n",
    "    time.sleep(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07e2ea8-fc7a-4da8-8929-6f5a3d2f7e77",
   "metadata": {},
   "source": [
    "## Playground <a class=\"anchor\" id=\"playground\"></a>\n",
    "\n",
    "Try out stuff yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883ff592-c9d4-4717-9927-650d3cead0fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
